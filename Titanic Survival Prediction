# Titanic Survival Prediction - New Style
# Author: Poornisha K

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import warnings
warnings.filterwarnings('ignore')

# ------------------- LOAD DATA -------------------
train = pd.read_csv(r'C:\Users\VSB-AIDSPC38\Downloads\PRODIGY_DS_02-main\PRODIGY_DS_02-main\nisha.py\train.csv')
test = pd.read_csv(r'C:\Users\VSB-AIDSPC38\Downloads\PRODIGY_DS_02-main\PRODIGY_DS_02-main\nisha.py\test.csv')

print("‚úÖ Data Loaded Successfully!")
print(f"Train Shape: {train.shape}, Test Shape: {test.shape}")
print("\nSample Rows:\n", train.head(3))

# ------------------- CLEAN DATA -------------------
# Fill missing values
train['Age'].fillna(train['Age'].median(), inplace=True)
test['Age'].fillna(test['Age'].median(), inplace=True)

train['Embarked'].fillna(train['Embarked'].mode()[0], inplace=True)
test['Fare'].fillna(test['Fare'].median(), inplace=True)

# Drop Cabin column
for dataset in [train, test]:
    if 'Cabin' in dataset.columns:
        dataset.drop('Cabin', axis=1, inplace=True)

# ------------------- FEATURE ENGINEERING -------------------
for dataset in [train, test]:
    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1
    dataset['IsAlone'] = np.where(dataset['FamilySize'] == 1, 1, 0)

    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
    dataset['Title'] = dataset['Title'].replace(['Lady','Countess','Capt','Col','Don','Dr','Major','Rev','Sir','Jonkheer','Dona'],'Rare')
    dataset['Title'] = dataset['Title'].replace(['Mlle','Ms'],'Miss')
    dataset['Title'] = dataset['Title'].replace('Mme','Mrs')

# Encode Categorical Columns
label = LabelEncoder()
for col in ['Sex', 'Embarked', 'Title']:
    for dataset in [train, test]:
        dataset[col] = label.fit_transform(dataset[col].astype(str))

# Drop unused columns
train.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)
test.drop(['Name','Ticket'], axis=1, inplace=True)

print("\n‚ú® Data Cleaning & Encoding Completed!")

# ------------------- CORRELATION HEATMAP -------------------
plt.figure(figsize=(10,6))
sns.heatmap(train.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title("Feature Correlation Heatmap")
plt.show()

# ------------------- FEATURE SELECTION -------------------
X = train.drop('Survived', axis=1)
y = train['Survived']

# Normalize numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ------------------- TRAIN/TEST SPLIT -------------------
X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# ------------------- MULTIPLE MODEL COMPARISON -------------------
models = {
    'Logistic Regression': LogisticRegression(max_iter=200),
    'Decision Tree': DecisionTreeClassifier(max_depth=5, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=120, random_state=42)
}

accuracy_scores = {}

print("\nüöÄ Model Training and Evaluation Started...\n")
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_valid)
    acc = accuracy_score(y_valid, preds)
    accuracy_scores[name] = acc
    print(f"‚úÖ {name} Accuracy: {acc*100:.2f}%")

# ------------------- ACCURACY COMPARISON BAR CHART -------------------
plt.figure(figsize=(8,5))
sns.barplot(x=list(accuracy_scores.keys()), y=list(accuracy_scores.values()), palette='viridis')
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.ylim(0.6, 1)
plt.show()

# ------------------- CONFUSION MATRIX (Best Model) -------------------
best_model_name = max(accuracy_scores, key=accuracy_scores.get)
best_model = models[best_model_name]
y_pred = best_model.predict(X_valid)

print(f"\nüèÜ Best Model: {best_model_name}")
print("\nConfusion Matrix:\n", confusion_matrix(y_valid, y_pred))
print("\nClassification Report:\n", classification_report(y_valid, y_pred))

# ------------------- PREDICT TEST DATA -------------------
test_scaled = scaler.transform(test.drop('PassengerId', axis=1, errors='ignore'))
test_pred = best_model.predict(test_scaled)

output = pd.DataFrame({
    'PassengerId': test['PassengerId'],
    'Survived': test_pred
})
output.to_csv('poornisha_titanic_new_output.csv', index=False)
print("\nüìÇ Output Saved as 'poornisha_titanic_new_output.csv'")

# ------------------- SURVIVAL PROBABILITY PLOT -------------------
plt.figure(figsize=(8,5))
survival_probs = best_model.predict_proba(X_valid)[:,1]
sns.histplot(survival_probs, bins=20, kde=True, color='teal')
plt.title("Predicted Survival Probabilities")
plt.xlabel("Probability of Survival")
plt.ylabel("Number of Passengers")
plt.show()


